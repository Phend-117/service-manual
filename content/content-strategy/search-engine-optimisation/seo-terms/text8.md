---
layout: text/textblock
---
Also called crawlers, web crawlers, and spiders. These are programs that browse your web pages and collect data from and about them. Robots such as ‘googlebot’ collect hundreds of pieces of information about every single web page they visit. This data feeds back into the search engine to help it work out the best search results to display for each search.

